# ğŸ§ª mlops-data-versioning-lab

A hands-on MLOps lab demonstrating dataset versioning, reproducibility, and rollback using DVC and DagsHub, with extensions into orchestration and cloud storage backends.

**This repository focuses on data lifecycle management, not model training.**

---

## ğŸ¯ What This Repo Is About

Modern ML systems fail more often due to **data issues** than model issues.

This lab shows how to:

- âœ… Version datasets safely (v1 â†’ v2 â†’ v3)
- âœ… Roll back to a stable dataset when experiments fail
- âœ… Store large data outside Git using remote storage
- âœ… Keep experiments reproducible and auditable
- âœ… Extend the same pipeline to orchestration and cloud setups

---

## ğŸŒ¿ Branch Structure (Very Important)

### ğŸ”¹ `master` / `main` â€” Core Data Versioning

**Status:** Stable  
**Focus:** DVC + DagsHub integration

- Dataset versions tracked via Git tags (`data-v1`, `data-v2`, `data-v3`)
- DagsHub S3 used as remote data storage
- Demonstrates rollback without recomputation

ğŸ‘‰ **This branch is the foundation of the repo.**

### ğŸ”¹ `dagster-redpanda` â€” Orchestration Layer

**Status:** Extension  
**Focus:** Data orchestration & streaming

- Dagster for data orchestration
- Redpanda for stream/event-driven ingestion
- Focus on data movement & pipelines
- DVC remains the single source of truth for data versions

ğŸ‘‰ **Shows how versioned data fits into orchestrated systems.**

### ğŸ”¹ `aws-dvc` â€” Cloud Backend Variant

**Status:** Extension  
**Focus:** Enterprise cloud storage

- DVC remote switched from DagsHub S3 â†’ AWS S3
- Same pipeline, different storage backend
- Enterprise-style cloud configuration

ğŸ‘‰ **Shows how storage can change without changing pipelines.**

---

## ğŸ“ Project Structure (Master Branch)

```
mlops-data-versioning-lab/
â”œâ”€â”€ data/tabular/raw/        # DVC-tracked data (NOT in Git)
â”œâ”€â”€ reports/                 # DVC-tracked outputs
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ make_tabular_data.py # Dataset generator
â”‚   â””â”€â”€ profile_tabular.py   # Data profiler
â”œâ”€â”€ orchestration/           # Dagster assets (other branch)
â”‚   â””â”€â”€ dagster_app/
â”‚       â”œâ”€â”€ assets.py
â”‚       â””â”€â”€ definitions.py
â”œâ”€â”€ dvc.yaml                 # Pipeline definition
â”œâ”€â”€ dvc.lock                 # Exact data hashes (critical)
â”œâ”€â”€ params.yaml              # Dataset configuration
â”œâ”€â”€ workspace.yaml           # Dagster workspace
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Git
- DVC
- DagsHub account (free)

### Installation

```bash
# Clone the repository
git clone https://github.com/scai-learning-hub/mlops-data-versioning-lab.git
cd mlops-data-versioning-lab

# Install dependencies
pip install -r requirements.txt

# Initialize DVC (if not already done)
dvc remote add origin <your-dagshub-s3-url>

# Pull data from remote
dvc pull
```

---

## ğŸ” Dataset Versioning Workflow

### Creating a New Dataset Version

```bash
# Modify parameters in params.yaml (e.g., change n_samples)
# Regenerate the dataset
dvc repro

# Commit the changes
git add dvc.lock params.yaml
git commit -m "data-v2: increased samples to 7000"
git tag data-v2

# Push to Git and DVC remote
git push
git push --tags
dvc push
```

Each version is:
- **Immutable** â€” Can't be changed
- **Traceable** â€” Git history shows when/why
- **Reproducible** â€” Exact same data every time

---

## ğŸ”„ Rollback (Core Concept)

### Roll Back to a Previous Dataset

```bash
# Switch to a previous data version
git checkout data-v1
dvc checkout
```

**What happens:**
1. Git switches metadata (`dvc.lock`, `params.yaml`)
2. DVC restores the exact dataset snapshot
3. Data is pulled from remote storage if missing locally
4. **No regeneration, no recomputation**

### Return to Latest

```bash
git checkout master
dvc checkout
```

---

## ğŸ§  How This Works in Real ML Systems

**Typical flow:**

```
data-v1 â†’ train â†’ metrics OK âœ…
data-v2 â†’ train â†’ metrics improved âœ…
data-v3 â†’ train â†’ metrics drop âŒ
rollback â†’ data-v2 â†’ retrain âœ…
```

Each training run:
- Creates a new experiment
- Uses a **known dataset version**
- Is fully reproducible later

---

## â˜ï¸ Storage Strategy

| Storage Backend | Branch | Use Case |
|----------------|--------|----------|
| **DagsHub S3** | `master` | Default, managed, simple |
| **AWS S3** | `aws-dvc` | Enterprise setup |

**Key points:**
- Data is **never stored in Git**
- Git only tracks **metadata & pointers**
- Large files stay in remote storage

---

## ğŸ§ª Pipeline Stages

### 1. Generate Dataset

```bash
dvc repro generate
```

- Generates synthetic tabular data
- Configured via `params.yaml`
- Outputs to `data/tabular/raw/dataset.csv`

### 2. Profile Dataset

```bash
dvc repro profile
```

- Creates data quality report
- Outputs to `reports/profile.json`

### Run Entire Pipeline

```bash
dvc repro
```

---

## ğŸš« Out of Scope (By Design)

This repo intentionally excludes:

- âŒ Model training
- âŒ Hyperparameter tuning
- âŒ Model deployment
- âŒ Production inference

**Why?** This repo is about **data correctness first**. Models come later.

---

## ğŸ§ª Who This Repo Is For

- ğŸ“ MLOps learners
- ğŸ’¼ Engineers preparing for interviews
- ğŸ¢ Teams building reproducible ML pipelines
- ğŸ”¬ Anyone who wants to understand **data rollback done right**

---

## ğŸ“š Related Resources

- [DVC Documentation](https://dvc.org/doc)
- [DagsHub Documentation](https://dagshub.com/docs)
- [Dagster Documentation](https://docs.dagster.io)

---

## âœ… Key Takeaway

> **Models change. Code changes.**  
> **But without versioned data, nothing is reproducible.**

---

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ¤ Contributing

This is a learning repository. Feel free to:
- Fork and experiment
- Submit PRs for improvements
- Open issues for questions

---

## ğŸ“§ Contact

For questions or discussions, open an issue on GitHub.

---

**Made with â¤ï¸ for the MLOps community**
